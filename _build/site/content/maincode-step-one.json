{"version":2,"kind":"Notebook","sha256":"7f1fd8e313e42c6fab45c3da57bcb668314d044225806c0626207dd37137a2f4","slug":"maincode-step-one","location":"/Notebooks/Maincode_Step_one.ipynb","dependencies":[],"frontmatter":{"kernelspec":{"name":"python3","display_name":"Python 3"},"authors":[{"id":"Luuk Fröling","name":"Luuk Fröling"}],"date":"2025-11-17","github":"https://github.com/luukfroling/BEP","exports":[{"format":"ipynb","filename":"Maincode_Step_one.ipynb","url":"/Maincode_Step_one-177b08222eef95375810988cce6d9268.ipynb"}]},"widgets":{"application/vnd.jupyter.widget-state+json":{"002327f8a2c245b1a8432f233c145d17":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"02fbeecd61fe4cd6b5f33761e1490880":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"04a0607ccc07463094e5182a9e5cf2f1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0741f65fd1ed46a58d488b125c72cbbc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"098463c2c4ac4120bb412069b88e9c55":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1424acaef2bf461a8fde85593717c735":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d2af0bb2013468dbbe7abe22f4fcde0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b0e6d43fc474223a8c1dadee3fb6035":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c6db8960d6244609f069620d82e4a27","placeholder":"​","style":"IPY_MODEL_1d2af0bb2013468dbbe7abe22f4fcde0","value":" 4010957/4010957 [00:06&lt;00:00, 466653.43 examples/s]"}},"2fc2307ecd574d69ab9d3cfba8fb5ca2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"338fcbaa55fc45d692d4280264c4b42b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1424acaef2bf461a8fde85593717c735","placeholder":"​","style":"IPY_MODEL_99793063eb1f4fa792b70cb35f23577d","value":"README.md: "}},"5ce616bfbfd14a0c85a7ed776dc81d6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee28b98730bf4e1f88423ecf98bff609","placeholder":"​","style":"IPY_MODEL_7f04c3b6d5bb461ab246fd30ac32982b","value":" 1.64k/? [00:00&lt;00:00, 133kB/s]"}},"615fa8c6587a43b89cf09745891188aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"69d80fc07a6f4b22b17d63fdad33bbad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_098463c2c4ac4120bb412069b88e9c55","placeholder":"​","style":"IPY_MODEL_2fc2307ecd574d69ab9d3cfba8fb5ca2","value":" 426M/426M [00:04&lt;00:00, 182MB/s]"}},"6c6db8960d6244609f069620d82e4a27":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b17cdf9a5284563b2e6517a8a4d8f38":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_913e617781224813a808655cbe04acc2","placeholder":"​","style":"IPY_MODEL_be9b5ef5f2fa4597acd751c1fac2e664","value":"Generating train split: 100%"}},"7f04c3b6d5bb461ab246fd30ac32982b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"883f3ae6fd8d4819b3001014f0de7af5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fc7e66db62e45c79d296e00823bf0ba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"913e617781224813a808655cbe04acc2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"939daed7b9f64db784d59ec10a1c2de4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99793063eb1f4fa792b70cb35f23577d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b744ef4e3c284fbd892d02f919084d50":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e873c18bf0bb45879be38b34c7b68885","IPY_MODEL_c43510a40dd241e590fbf41f30847e76","IPY_MODEL_69d80fc07a6f4b22b17d63fdad33bbad"],"layout":"IPY_MODEL_883f3ae6fd8d4819b3001014f0de7af5"}},"be9b5ef5f2fa4597acd751c1fac2e664":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c43510a40dd241e590fbf41f30847e76":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_939daed7b9f64db784d59ec10a1c2de4","max":425544090,"min":0,"orientation":"horizontal","style":"IPY_MODEL_02fbeecd61fe4cd6b5f33761e1490880","value":425544090}},"c73453487e7e4efe9e617eb205da8139":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b17cdf9a5284563b2e6517a8a4d8f38","IPY_MODEL_f023ed70472e4f68b3d873de99fd10cb","IPY_MODEL_2b0e6d43fc474223a8c1dadee3fb6035"],"layout":"IPY_MODEL_d5301b5d73284742b13214500390a741"}},"d498f1da1ce44b43b1ab5e4a9f98700c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5301b5d73284742b13214500390a741":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e41b55af5edb47449e82e7611edb73d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_002327f8a2c245b1a8432f233c145d17","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_615fa8c6587a43b89cf09745891188aa","value":1}},"e873c18bf0bb45879be38b34c7b68885":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04a0607ccc07463094e5182a9e5cf2f1","placeholder":"​","style":"IPY_MODEL_eb54678d379d4d0189b89fa8081e7209","value":"story.parquet: 100%"}},"eb54678d379d4d0189b89fa8081e7209":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed3ec9fd34fd40f7a5cd14d0a1b677cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_338fcbaa55fc45d692d4280264c4b42b","IPY_MODEL_e41b55af5edb47449e82e7611edb73d8","IPY_MODEL_5ce616bfbfd14a0c85a7ed776dc81d6b"],"layout":"IPY_MODEL_d498f1da1ce44b43b1ab5e4a9f98700c"}},"ee28b98730bf4e1f88423ecf98bff609":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f023ed70472e4f68b3d873de99fd10cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fc7e66db62e45c79d296e00823bf0ba","max":4010957,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0741f65fd1ed46a58d488b125c72cbbc","value":4010957}}}},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-code","data":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1qUmg3_DFtYG","outputId":"6c777f81-b5f3-4f37-8467-fbf4a5ceb809"},"children":[{"type":"code","lang":"python","executable":true,"value":"!pip install torch --index-url https://download.pytorch.org/whl/cu121\n!pip install datasets tokenizers structlog tqdm utils\n\nimport utils\nimport math, random, time\nfrom dataclasses import dataclass\nimport json\nfrom pathlib import Path\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom datasets import load_dataset\nfrom tokenizers import Tokenizer, models, trainers, pre_tokenizers, decoders\nfrom tqdm import tqdm\nimport structlog","identifier":"1qumg3_dftyg-code","enumerator":"1","html_id":"id-1qumg3-dftyg-code","key":"xyptN7XQ6I"},{"type":"output","id":"jL67GC8V8yZy_TUdBCua1","data":[{"name":"stdout","output_type":"stream","text":"Looking in indexes: https://download.pytorch.org/whl/cu121\nRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\nRequirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\nRequirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (0.22.1)\nCollecting structlog\n  Downloading structlog-25.5.0-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\nCollecting utils\n  Downloading utils-1.0.2.tar.gz (13 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.10.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nDownloading structlog-25.5.0-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: utils\n  Building wheel for utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for utils: filename=utils-1.0.2-py2.py3-none-any.whl size=13906 sha256=7b225dc0dbab6db03b334f39ab0b722006fc3ee52f4a64cfbeb1d0360bd031c9\n  Stored in directory: /root/.cache/pip/wheels/b6/a1/81/1036477786ae0e17b522f6f5a838f9bc4288d1016fc5d0e1ec\nSuccessfully built utils\nInstalling collected packages: utils, structlog\nSuccessfully installed structlog-25.5.0 utils-1.0.2\n"}],"identifier":"1qumg3_dftyg-output","html_id":"id-1qumg3-dftyg-output","key":"tJX3EiR0em"}],"identifier":"1qumg3_dftyg","label":"1qUmg3_DFtYG","html_id":"id-1qumg3-dftyg","key":"cE2fuTRkPi"},{"type":"block","kind":"notebook-code","data":{"colab":{"base_uri":"https://localhost:8080/","height":862,"referenced_widgets":["ed3ec9fd34fd40f7a5cd14d0a1b677cd","338fcbaa55fc45d692d4280264c4b42b","e41b55af5edb47449e82e7611edb73d8","5ce616bfbfd14a0c85a7ed776dc81d6b","d498f1da1ce44b43b1ab5e4a9f98700c","1424acaef2bf461a8fde85593717c735","99793063eb1f4fa792b70cb35f23577d","002327f8a2c245b1a8432f233c145d17","615fa8c6587a43b89cf09745891188aa","ee28b98730bf4e1f88423ecf98bff609","7f04c3b6d5bb461ab246fd30ac32982b","b744ef4e3c284fbd892d02f919084d50","e873c18bf0bb45879be38b34c7b68885","c43510a40dd241e590fbf41f30847e76","69d80fc07a6f4b22b17d63fdad33bbad","883f3ae6fd8d4819b3001014f0de7af5","04a0607ccc07463094e5182a9e5cf2f1","eb54678d379d4d0189b89fa8081e7209","939daed7b9f64db784d59ec10a1c2de4","02fbeecd61fe4cd6b5f33761e1490880","098463c2c4ac4120bb412069b88e9c55","2fc2307ecd574d69ab9d3cfba8fb5ca2","c73453487e7e4efe9e617eb205da8139","7b17cdf9a5284563b2e6517a8a4d8f38","f023ed70472e4f68b3d873de99fd10cb","2b0e6d43fc474223a8c1dadee3fb6035","d5301b5d73284742b13214500390a741","913e617781224813a808655cbe04acc2","be9b5ef5f2fa4597acd751c1fac2e664","8fc7e66db62e45c79d296e00823bf0ba","0741f65fd1ed46a58d488b125c72cbbc","6c6db8960d6244609f069620d82e4a27","1d2af0bb2013468dbbe7abe22f4fcde0"]},"id":"-_jl113qF2hO","outputId":"c5bc5fe2-7729-42da-cb40-51d4c96e7f7c"},"children":[{"type":"code","lang":"python","executable":true,"value":"# CODE ADDED BY ME\n\n#Plotting the loss will allow us to nicely display the loss in a Jupyter Book.\nloss_tracker = []\n\n# Add different optimiser, which is better suited for transformer models\ndef get_optimizer(model, args):\n    # Add AdamW as an optimiser\n    return torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay, betas=args.betas)\n\n# CODE FROM GITHUB\n@dataclass\nclass Hyperparameters:\n    block_size: int = 128\n    batch_size: int = 64\n    vocab_size: int = 16_000\n    n_layer: int = 6\n    n_head: int = 8\n    d_model: int = 512\n    dropout: float = 0.1\n    lr = 5e-4                   #lr: float = 6e-3, \n    weight_decay: float = 0.0\n    evals_per_epoch: int = 3\n    betas = (0.9, 0.95)         # Added betas for AdamW\n\n    epochs: int = 7\n    seed: int = 1337\n    num_titles: int = 100_000\n    val_frac: float = 0.10\n    log_file: str = \"./logs/mainrun.log\"\n\ndef configure_logging(log_file: str):\n    Path(log_file).parent.mkdir(parents=True, exist_ok=True)\n\n    file_handler = open(log_file, 'w')\n\n    structlog.configure(\n        processors=[\n            structlog.stdlib.filter_by_level,\n            structlog.stdlib.add_logger_name,\n            structlog.stdlib.add_log_level,\n            structlog.stdlib.PositionalArgumentsFormatter(),\n            structlog.processors.TimeStamper(fmt=\"iso\"),\n            structlog.processors.StackInfoRenderer(),\n            structlog.processors.format_exc_info,\n            structlog.processors.UnicodeDecoder(),\n            structlog.processors.JSONRenderer()\n        ],\n        context_class=dict,\n        logger_factory=structlog.stdlib.LoggerFactory(),\n        cache_logger_on_first_use=True,\n    )\n\n    class DualLogger:\n        def __init__(self, file_handler):\n            self.file_handler = file_handler\n            self.logger = structlog.get_logger()\n\n        def log(self, event, **kwargs):\n            log_entry = json.dumps({\"event\": event, \"timestamp\": time.time(), **kwargs})\n            self.file_handler.write(log_entry + \"\\n\")\n            self.file_handler.flush()\n\n            if kwargs.get(\"prnt\", True):\n                if \"step\" in kwargs and \"max_steps\" in kwargs:\n                    tqdm.write(f\"[{kwargs.get('step'):>5}/{kwargs.get('max_steps')}] {event}: loss={kwargs.get('loss', 'N/A'):.6f} time={kwargs.get('elapsed_time', 0):.2f}s\")\n                else:\n                    parts = [f\"{k}={v}\" for k, v in kwargs.items() if k not in [\"prnt\", \"timestamp\"]]\n                    if parts:\n                        tqdm.write(f\"{event}: {', '.join(parts)}\")\n                    else:\n                        tqdm.write(event)\n\n    return DualLogger(file_handler)\n\nlogger = None\n\ndef get_titles(num_titles: int, seed: int, val_frac: float) -> str:\n    ds = load_dataset(\"julien040/hacker-news-posts\", split=\"train\", cache_dir=\"./data\").shuffle(seed=seed)\n    titles = [row[\"title\"].strip() for row in ds.take(num_titles)]\n    n = int(num_titles * (1 - val_frac))\n    return titles[:n], titles[n:]\n\ndef get_batch(split_ids: torch.Tensor, ptr: int, block_size: int, batch_size: int, device: torch.device):\n    span = block_size * batch_size + 1\n    if ptr + span >= len(split_ids):\n        ptr = 0\n    batch = split_ids[ptr: ptr + span]\n    x = batch[:-1].view(batch_size, block_size).to(device)\n    y = batch[1:].view(batch_size, block_size).to(device)\n    return x, y, ptr + block_size * batch_size\n\ndef iter_full_split(split_ids: torch.Tensor, block_size: int, batch_size: int, device: torch.device):\n    span = block_size * batch_size + 1\n    for ptr in range(0, len(split_ids) - span + 1, span):\n        batch = split_ids[ptr: ptr + span]\n        x = batch[:-1].view(batch_size, block_size).to(device)\n        y = batch[1:].view(batch_size, block_size).to(device)\n        yield x, y\n\ndef train_tokenizer(titles: list[str], vocab_size: int, unk_token: str = \"<unk>\", pad_token: str = \"<pad>\", eos_token: str = \"<eos>\") -> Tokenizer:\n    tokenizer = Tokenizer(models.BPE(unk_token=unk_token))\n    tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n    tokenizer.decoder = decoders.ByteLevel()\n    trainer = trainers.BpeTrainer(\n        vocab_size=vocab_size,\n        special_tokens=[pad_token, eos_token, unk_token]\n    )\n    tokenizer.train_from_iterator(titles, trainer)\n    return tokenizer\n\nclass BPETokenizer:\n    def __init__(self, tokenizer: Tokenizer):\n        self.tk = tokenizer\n        self.stoi = {tok: i for tok, i in tokenizer.get_vocab().items()}\n        self.itos = {i: tok for tok, i in tokenizer.get_vocab().items()}\n\n    def encode(self, s: str) -> list[int]:\n        return self.tk.encode(s).ids\n\n    def decode(self, ids: list[int]) -> str:\n        return self.tk.decode(ids, skip_special_tokens=True)\n\n    @property\n    def vocab_size(self): return self.tk.get_vocab_size()\n\n@dataclass\nclass GPTConfig:\n    vocab_size: int\n    block_size: int\n    n_layer: int\n    n_head: int\n    d_model: int\n    dropout: float\n\nclass CausalSelfAttention(nn.Module):\n    def __init__(self, cfg: GPTConfig):\n        super().__init__()\n        assert cfg.d_model % cfg.n_head == 0\n        self.head_dim = cfg.d_model // cfg.n_head\n        self.n_head   = cfg.n_head\n        self.qkv = nn.Linear(cfg.d_model, 3 * cfg.d_model)\n        self.proj = nn.Linear(cfg.d_model, cfg.d_model)\n        self.attn_drop = nn.Dropout(cfg.dropout)\n        self.resid_drop= nn.Dropout(cfg.dropout)\n        self.register_buffer(\"tril\", torch.tril(torch.ones(cfg.block_size, cfg.block_size)))\n\n    def forward(self, x: torch.Tensor):\n        B, T, C = x.size()\n        qkv = self.qkv(x).view(B, T, 3, self.n_head, self.head_dim).transpose(1, 3)\n        q, k, v = qkv[..., 0, :, :], qkv[..., 1, :, :], qkv[..., 2, :, :]\n        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n        att = att.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\"))\n        att = F.softmax(att, dim=-1)\n        att = self.attn_drop(att)\n        y = att @ v\n        y = y.transpose(1, 2).contiguous().view(B, T, C)\n        return self.resid_drop(self.proj(y))\n\nclass MLP(nn.Module):\n    def __init__(self, cfg: GPTConfig):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(cfg.d_model, 4 * cfg.d_model),\n            nn.GELU(),\n            nn.Linear(4 * cfg.d_model, cfg.d_model),\n            nn.Dropout(cfg.dropout),\n        )\n    def forward(self, x): return self.net(x)\n\nclass Block(nn.Module):\n    def __init__(self, cfg: GPTConfig):\n        super().__init__()\n        self.ln1 = nn.LayerNorm(cfg.d_model)\n        self.ln2 = nn.LayerNorm(cfg.d_model)\n        self.attn = CausalSelfAttention(cfg)\n        self.mlp  = MLP(cfg)\n    def forward(self, x):\n        x = x + self.attn(self.ln1(x))\n        x = x + self.mlp(self.ln2(x))\n        return x\n\nclass GPT(nn.Module):\n    def __init__(self, cfg: GPTConfig):\n        super().__init__()\n        self.cfg = cfg\n        self.token_emb = nn.Embedding(cfg.vocab_size, cfg.d_model)\n        self.pos_emb   = nn.Parameter(torch.zeros(1, cfg.block_size, cfg.d_model))\n        self.drop      = nn.Dropout(cfg.dropout)\n        self.blocks    = nn.ModuleList([Block(cfg) for _ in range(cfg.n_layer)])\n        self.ln_f      = nn.LayerNorm(cfg.d_model)\n        self.head      = nn.Linear(cfg.d_model, cfg.vocab_size, bias=False)\n\n        self.apply(self._init_weights)\n        self.head.weight = self.token_emb.weight\n\n    @staticmethod\n    def _init_weights(module):\n        if isinstance(module, (nn.Linear, nn.Embedding)):\n            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n            if isinstance(module, nn.Linear) and module.bias is not None:\n                nn.init.zeros_(module.bias)\n\n    def forward(self, idx: torch.Tensor, targets: torch.Tensor | None = None):\n        B, T = idx.size()\n        tok = self.token_emb(idx)\n        pos = self.pos_emb[:, :T, :]\n        x = self.drop(tok + pos)\n        for block in self.blocks: x = block(x)\n        x = self.ln_f(x)\n        logits = self.head(x)\n        if targets is None:\n            loss = None\n        else:\n            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), reduction='mean')\n        return logits, loss\n\nargs = Hyperparameters()\ntorch.manual_seed(args.seed)\nrandom.seed(args.seed)\n\nglobal logger\nlogger = configure_logging(args.log_file)\n\nhyperparams_dict = vars(args)\nlogger.log(\"hyperparameters_configured\", **hyperparams_dict)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nlogger.log(\"device_info\", device=device)\n\ntrain_titles, val_titles = get_titles(args.num_titles, args.seed, args.val_frac)\n\neos_token = \"<eos>\"\ntok = BPETokenizer(train_tokenizer(train_titles+val_titles, args.vocab_size, eos_token=eos_token))\ntrain_text = eos_token.join(train_titles) + eos_token\nval_text = eos_token.join(val_titles) + eos_token\ntrain_ids = torch.tensor(tok.encode(train_text), dtype=torch.long)\nval_ids = torch.tensor(tok.encode(val_text), dtype=torch.long)\n\nbatches = len(train_ids) // (args.block_size * args.batch_size)\nmax_steps = args.epochs * batches\neval_interval = batches // args.evals_per_epoch\nlogger.log(\"dataset_info\",\n            titles_count=len(train_titles),\n            epochs=args.epochs,\n            batches_per_epoch=batches,\n            tokens_per_epoch=len(train_ids),\n            vocab_size=tok.vocab_size)\n\ncfg = GPTConfig(\n    vocab_size = tok.vocab_size,\n    block_size = args.block_size,\n    n_layer    = args.n_layer,\n    n_head     = args.n_head,\n    d_model    = args.d_model,\n    dropout    = args.dropout,\n)\nmodel = GPT(cfg).to(device)\nmodel_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nlogger.log(\"model_info\", parameters_count=model_params)\n\nopt = get_optimizer(model, args)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=max_steps)\n\ndef evaluate():\n    model.eval()\n    losses = 0.0\n    with torch.no_grad():\n        for xb, yb in iter_full_split(val_ids, args.block_size, args.batch_size, device):\n            logits, _ = model(xb, yb)\n            B, T, V = logits.size()\n            loss = F.cross_entropy(logits.view(-1, V), yb.view(-1), reduction='sum')\n            losses += loss.item()\n    model.train()\n    return losses / len(val_text)\n\nptr = 0\nstep = 0\nt0 = time.time()\nfor epoch in range(1, args.epochs + 1):\n    for _ in tqdm(range(1, batches + 1), desc=f\"Epoch {epoch}/{args.epochs}\"):\n        step += 1\n        xb, yb, ptr = get_batch(train_ids, ptr, args.block_size, args.batch_size, device)\n        _, loss = model(xb, yb)\n        opt.zero_grad(set_to_none=True)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        opt.step()\n        scheduler.step()\n\n        elapsed = time.time() - t0\n        logger.log(\"training_step\",\n                  step=step,\n                  max_steps=max_steps,\n                  loss=loss.item(),\n                  elapsed_time=elapsed,\n                  prnt=False)\n\n        if step == 1 or step % eval_interval == 0 or step == max_steps:\n            val_loss = evaluate()\n            loss_tracker.append(val_loss) # Line added by me\n            logger.log(\"validation_step\",\n                      step=step,\n                      max_steps=max_steps,\n                      loss=val_loss,\n                      elapsed_time=elapsed)","identifier":"-_jl113qf2ho-code","enumerator":"2","html_id":"id-jl113qf2ho-code","key":"ENKs9VLMIf"},{"type":"output","id":"Rt28jMwuCCFALMzq11Nlx","data":[{"name":"stdout","output_type":"stream","text":"hyperparameters_configured: block_size=128, batch_size=64, vocab_size=16000, n_layer=6, n_head=8, d_model=512, dropout=0.1, weight_decay=0.0, evals_per_epoch=3, epochs=7, seed=1337, num_titles=100000, val_frac=0.1, log_file=./logs/mainrun.log\ndevice_info: device=cuda\n"},{"name":"stderr","output_type":"stream","text":"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \nThe secret `HF_TOKEN` does not exist in your Colab secrets.\nTo authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\nYou will be able to reuse this secret in all of your notebooks.\nPlease note that authentication is recommended but still optional to access public models or datasets.\n  warnings.warn(\n"},{"output_type":"display_data","metadata":{},"data":{"application/vnd.jupyter.widget-view+json":{"content":"{\"model_id\":\"ed3ec9fd34fd40f7a5cd14d0a1b677cd\",\"version_major\":2,\"version_minor\":0}","content_type":"application/vnd.jupyter.widget-view+json"},"text/plain":{"content":"README.md: 0.00B [00:00, ?B/s]","content_type":"text/plain"}}},{"output_type":"display_data","metadata":{},"data":{"application/vnd.jupyter.widget-view+json":{"content":"{\"model_id\":\"b744ef4e3c284fbd892d02f919084d50\",\"version_major\":2,\"version_minor\":0}","content_type":"application/vnd.jupyter.widget-view+json"},"text/plain":{"content":"story.parquet:   0%|          | 0.00/426M [00:00<?, ?B/s]","content_type":"text/plain"}}},{"output_type":"display_data","metadata":{},"data":{"application/vnd.jupyter.widget-view+json":{"content":"{\"model_id\":\"c73453487e7e4efe9e617eb205da8139\",\"version_major\":2,\"version_minor\":0}","content_type":"application/vnd.jupyter.widget-view+json"},"text/plain":{"content":"Generating train split:   0%|          | 0/4010957 [00:00<?, ? examples/s]","content_type":"text/plain"}}},{"name":"stdout","output_type":"stream","text":"dataset_info: titles_count=90000, epochs=7, batches_per_epoch=134, tokens_per_epoch=1102455, vocab_size=16000\nmodel_info: parameters_count=27172864\n"},{"name":"stderr","output_type":"stream","text":"Epoch 1/7:   1%|          | 1/134 [00:03<06:56,  3.13s/it]"},{"name":"stdout","output_type":"stream","text":"[    1/938] validation_step: loss=1.959879 time=1.25s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 1/7:  33%|███▎      | 44/134 [00:22<01:28,  1.02it/s]"},{"name":"stdout","output_type":"stream","text":"[   44/938] validation_step: loss=1.614265 time=20.19s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 1/7:  66%|██████▌   | 88/134 [00:42<00:45,  1.00it/s]"},{"name":"stdout","output_type":"stream","text":"[   88/938] validation_step: loss=1.558035 time=40.15s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 1/7:  99%|█████████▊| 132/134 [01:02<00:02,  1.01s/it]"},{"name":"stdout","output_type":"stream","text":"[  132/938] validation_step: loss=1.495638 time=60.41s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 1/7: 100%|██████████| 134/134 [01:03<00:00,  2.11it/s]\nEpoch 2/7:  31%|███▏      | 42/134 [00:19<01:34,  1.03s/it]"},{"name":"stdout","output_type":"stream","text":"[  176/938] validation_step: loss=1.464094 time=81.03s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 2/7:  64%|██████▍   | 86/134 [00:40<00:49,  1.04s/it]"},{"name":"stdout","output_type":"stream","text":"[  220/938] validation_step: loss=1.437866 time=101.92s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 2/7:  97%|█████████▋| 130/134 [01:01<00:04,  1.05s/it]"},{"name":"stdout","output_type":"stream","text":"[  264/938] validation_step: loss=1.418996 time=122.98s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 2/7: 100%|██████████| 134/134 [01:03<00:00,  2.11it/s]\nEpoch 3/7:  30%|██▉       | 40/134 [00:19<01:38,  1.05s/it]"},{"name":"stdout","output_type":"stream","text":"[  308/938] validation_step: loss=1.405665 time=144.15s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 3/7:  63%|██████▎   | 84/134 [00:40<00:52,  1.05s/it]"},{"name":"stdout","output_type":"stream","text":"[  352/938] validation_step: loss=1.390493 time=165.26s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 3/7:  96%|█████████▌| 128/134 [01:01<00:06,  1.04s/it]"},{"name":"stdout","output_type":"stream","text":"[  396/938] validation_step: loss=1.378396 time=186.34s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 3/7: 100%|██████████| 134/134 [01:04<00:00,  2.09it/s]\nEpoch 4/7:  28%|██▊       | 38/134 [00:18<01:40,  1.04s/it]"},{"name":"stdout","output_type":"stream","text":"[  440/938] validation_step: loss=1.367200 time=207.43s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 4/7:  61%|██████    | 82/134 [00:39<00:54,  1.05s/it]"},{"name":"stdout","output_type":"stream","text":"[  484/938] validation_step: loss=1.356758 time=228.56s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 4/7:  94%|█████████▍| 126/134 [01:00<00:08,  1.05s/it]"},{"name":"stdout","output_type":"stream","text":"[  528/938] validation_step: loss=1.349252 time=249.73s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 4/7: 100%|██████████| 134/134 [01:04<00:00,  2.09it/s]\nEpoch 5/7:  27%|██▋       | 36/134 [00:17<01:42,  1.05s/it]"},{"name":"stdout","output_type":"stream","text":"[  572/938] validation_step: loss=1.342940 time=270.89s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 5/7:  60%|█████▉    | 80/134 [00:38<00:56,  1.05s/it]"},{"name":"stdout","output_type":"stream","text":"[  616/938] validation_step: loss=1.337759 time=292.06s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 5/7:  93%|█████████▎| 124/134 [01:00<00:10,  1.05s/it]"},{"name":"stdout","output_type":"stream","text":"[  660/938] validation_step: loss=1.333852 time=313.23s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 5/7: 100%|██████████| 134/134 [01:04<00:00,  2.08it/s]\nEpoch 6/7:  25%|██▌       | 34/134 [00:16<01:44,  1.05s/it]"},{"name":"stdout","output_type":"stream","text":"[  704/938] validation_step: loss=1.330137 time=334.39s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 6/7:  58%|█████▊    | 78/134 [00:37<00:58,  1.05s/it]"},{"name":"stdout","output_type":"stream","text":"[  748/938] validation_step: loss=1.327601 time=355.54s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 6/7:  91%|█████████ | 122/134 [00:59<00:12,  1.05s/it]"},{"name":"stdout","output_type":"stream","text":"[  792/938] validation_step: loss=1.325533 time=376.71s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 6/7: 100%|██████████| 134/134 [01:04<00:00,  2.08it/s]\nEpoch 7/7:  24%|██▍       | 32/134 [00:15<01:47,  1.05s/it]"},{"name":"stdout","output_type":"stream","text":"[  836/938] validation_step: loss=1.324688 time=397.87s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 7/7:  57%|█████▋    | 76/134 [00:37<01:00,  1.05s/it]"},{"name":"stdout","output_type":"stream","text":"[  880/938] validation_step: loss=1.323887 time=419.04s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 7/7:  90%|████████▉ | 120/134 [00:58<00:14,  1.05s/it]"},{"name":"stdout","output_type":"stream","text":"[  924/938] validation_step: loss=1.323863 time=440.22s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 7/7: 100%|██████████| 134/134 [01:06<00:00,  2.02it/s]"},{"name":"stdout","output_type":"stream","text":"[  938/938] validation_step: loss=1.323862 time=448.37s\n"},{"name":"stderr","output_type":"stream","text":"\n"}],"identifier":"-_jl113qf2ho-output","html_id":"id-jl113qf2ho-output","key":"ua3D0nK0SR"}],"identifier":"-_jl113qf2ho","label":"-_jl113qF2hO","html_id":"id-jl113qf2ho","key":"djxpjAUcXi"},{"type":"block","kind":"notebook-code","data":{"colab":{"base_uri":"https://localhost:8080/","height":726},"id":"tkYQPSAMcpfO","outputId":"b230dc6e-380f-42d0-ee30-3c075188ea93"},"children":[{"type":"code","lang":"python","executable":true,"value":"# |label: token_evaluate_frequency_first_step\nimport matplotlib.pyplot as plt\n\n# Function to evaluate and visualise top-10 token predictions for a given input from the validation set\ndef evaluate_visualise():\n    \n    model.eval()\n\n    with torch.no_grad():\n        for xb, yb in iter_full_split(val_ids, args.block_size, args.batch_size, device):\n\n            logits, _ = model(xb, yb)\n\n            b = 0 # batch\n            t = 10  # timestep\n\n            probs = torch.softmax(logits[b], dim=-1)   # (T, V) out\n\n            # top 10 tokens\n            top_probs, top_ids = probs[t].topk(10)\n\n            # decode token strings\n            decoded_tokens = [tok.tk.decode([tid.item()], skip_special_tokens=False) for tid in top_ids ]\n\n            # Print for debugging\n            print(\"\\nTop-10 predictions at t =\", t)\n            for rank in range(10):\n                print(f\"{rank+1}. p={top_probs[rank].item():.4f} | id={top_ids[rank].item()} | '{decoded_tokens[rank]}'\")\n\n            # plt histogram\n            plt.figure(figsize=(12, 5))\n            plt.bar(decoded_tokens, top_probs.cpu().tolist())\n            plt.title(f\"Top-10 Next-Token Predictions (t={t})\")\n            plt.xlabel(\"Token\")\n            plt.ylabel(\"Probability\")\n            plt.xticks(rotation=45, ha='right')\n            plt.tight_layout()\n            plt.show()\n\n            break  # only once\n\n\nevaluate_visualise()","identifier":"step_one_words-code","enumerator":"3","html_id":"step-one-words-code","key":"wbyLqF4yXK"},{"type":"output","id":"lanWxxCCJq6w71WNJQ_TK","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"caf20c53206bb6be0aa80d9e85b054d4","path":"/caf20c53206bb6be0aa80d9e85b054d4.png"},"text/plain":{"content":"<Figure size 1200x500 with 1 Axes>","content_type":"text/plain"}}}],"identifier":"step_one_words-output","html_id":"step-one-words-output","key":"YEzy1rbbIt"}],"identifier":"step_one_words","label":"step_one_words","html_id":"step-one-words","key":"DPlkfO6zay"},{"type":"block","kind":"notebook-code","data":{"colab":{"base_uri":"https://localhost:8080/","height":430},"id":"DnIeCJhrcomW","outputId":"5000fb41-6e1a-43f8-b17e-f52127fd66f0"},"children":[{"type":"code","lang":"python","executable":true,"value":"# |label: output-first-step\nimport matplotlib.pyplot as plt\n\nplt.plot(loss_tracker)\nplt.show()","identifier":"dniecjhrcomw-code","enumerator":"4","html_id":"dniecjhrcomw-code","key":"klvNOuBiAl"},{"type":"output","id":"u0EyTkchFio6QCyNLfj5u","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"df90b15c84447a8c43773070815ce569","path":"/df90b15c84447a8c43773070815ce569.png"},"text/plain":{"content":"<Figure size 640x480 with 1 Axes>","content_type":"text/plain"}}}],"identifier":"dniecjhrcomw-output","html_id":"dniecjhrcomw-output","key":"PUFzZto4er"}],"identifier":"dniecjhrcomw","label":"DnIeCJhrcomW","html_id":"dniecjhrcomw","key":"I0fsMoXl54"}],"key":"Z5SSPPXcVL"},"references":{"cite":{"order":[],"data":{}}}}