{"version":2,"kind":"Notebook","sha256":"1acfc34425148c1c923840039379dad4718016fa0cb36c68d5bd724257a5bb88","slug":"maincode-step-two","location":"/Notebooks/Maincode_Step_two.ipynb","dependencies":[],"frontmatter":{"kernelspec":{"name":"python3","display_name":"Python 3"},"authors":[{"id":"Luuk Fröling","name":"Luuk Fröling"}],"date":"2025-11-17","github":"https://github.com/luukfroling/BEP","exports":[{"format":"ipynb","filename":"Maincode_Step_two.ipynb","url":"/Maincode_Step_two-2792249cf422e95aaa48a0a61eaa152c.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-code","data":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zL4idQ2FIgnJ","outputId":"ab88c682-4f3a-49f8-d738-a1dc7f04354d"},"children":[{"type":"code","lang":"python","executable":true,"value":"!pip install torch --index-url https://download.pytorch.org/whl/cu121\n!pip install datasets tokenizers structlog tqdm utils\n\nimport utils\nimport math, random, time\nfrom dataclasses import dataclass\nimport json\nfrom pathlib import Path\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom datasets import load_dataset\nfrom tokenizers import Tokenizer, models, trainers, pre_tokenizers, decoders\nfrom tqdm import tqdm\nimport structlog","identifier":"zl4idq2fignj-code","enumerator":"1","html_id":"zl4idq2fignj-code","key":"qyQbIFyICG"},{"type":"output","id":"edyCCAvneu0h-nPi7wXjj","data":[{"name":"stdout","output_type":"stream","text":"Looking in indexes: https://download.pytorch.org/whl/cu121\nRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\nRequirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\nRequirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (0.22.1)\nCollecting structlog\n  Downloading structlog-25.5.0-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\nCollecting utils\n  Downloading utils-1.0.2.tar.gz (13 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.10.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nDownloading structlog-25.5.0-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: utils\n  Building wheel for utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for utils: filename=utils-1.0.2-py2.py3-none-any.whl size=13906 sha256=d670d133372189834dd4f76435ade33efdc976bd9c681e9b6ba00efbb9d70ee1\n  Stored in directory: /root/.cache/pip/wheels/b6/a1/81/1036477786ae0e17b522f6f5a838f9bc4288d1016fc5d0e1ec\nSuccessfully built utils\nInstalling collected packages: utils, structlog\nSuccessfully installed structlog-25.5.0 utils-1.0.2\n"}],"identifier":"zl4idq2fignj-output","html_id":"zl4idq2fignj-output","key":"nXFJDZXDDF"}],"identifier":"zl4idq2fignj","label":"zL4idQ2FIgnJ","html_id":"zl4idq2fignj","key":"h31nZ85Woc"},{"type":"block","kind":"notebook-code","data":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PreBnMv-Ilrf","outputId":"8fd08725-0eae-472c-f1ea-0c5d37018f8e"},"children":[{"type":"code","lang":"python","executable":true,"value":"# CODE ADDED BY ME\nfrom torch.nn import RMSNorm\n\n#Plotting the loss will allow us to nicely display the loss in a Jupyter Book.\nloss_tracker = []\n\n# Add different optimiser, which is better suited for transformer models\ndef get_optimizer(model, args):\n    return torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay, betas=args.betas)\n\n# Add learning rate scheduler (currently still the same as before)\ndef get_scheduler(opt):\n  return torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=max_steps)\n\n# Use RMSNorm instead of LayerNorm - more efficient for transformer models\ndef get_norm(d_model):\n  return RMSNorm(d_model)\n\n# RoPE implementation, allows the model to better capture positional information\ndef apply_rope(x):\n    # x shape: (B, n_head, T, head_dim)\n    B, H, T, D = x.shape\n    half = D // 2\n\n    # Split into two halves\n    x1 = x[..., :half]\n    x2 = x[..., half:]\n\n    # Create rotation frequencies\n    theta = 1.0 / (10000 ** (torch.arange(0, half, device=x.device) / half)) # 10000 given online\n    pos = torch.arange(T, device=x.device).unsqueeze(1)\n\n    # Compute angles\n    angle = pos * theta  # (T, half)\n\n    cos = angle.cos()[None, None, :, :]   # (1,1,T,half)\n    sin = angle.sin()[None, None, :, :]   # (1,1,T,half)\n\n    # Apply rotation\n    x_rotated = torch.cat([x1 * cos - x2 * sin,\n                           x1 * sin + x2 * cos], dim=-1)\n    return x_rotated\n\n# CODE FROM GITHUB\n@dataclass\nclass Hyperparameters:\n    block_size: int = 128\n    batch_size: int = 64\n    vocab_size: int = 32_000\n    n_layer = 4\n    n_head  = 4\n    d_model = 512\n    dropout: float = 0.1\n    lr = 5e-4                   #lr: float = 6e-3, decreased\n    weight_decay: float = 0.1\n    evals_per_epoch: int = 3\n    betas = (0.9, 0.99)         # Added betas (increased)\n\n    epochs: int = 7\n    seed: int = 1337\n    num_titles: int = 100_000\n    val_frac: float = 0.10\n    log_file: str = \"./logs/mainrun.log\"\n\ndef configure_logging(log_file: str):\n    Path(log_file).parent.mkdir(parents=True, exist_ok=True)\n\n    file_handler = open(log_file, 'w')\n\n    structlog.configure(\n        processors=[\n            structlog.stdlib.filter_by_level,\n            structlog.stdlib.add_logger_name,\n            structlog.stdlib.add_log_level,\n            structlog.stdlib.PositionalArgumentsFormatter(),\n            structlog.processors.TimeStamper(fmt=\"iso\"),\n            structlog.processors.StackInfoRenderer(),\n            structlog.processors.format_exc_info,\n            structlog.processors.UnicodeDecoder(),\n            structlog.processors.JSONRenderer()\n        ],\n        context_class=dict,\n        logger_factory=structlog.stdlib.LoggerFactory(),\n        cache_logger_on_first_use=True,\n    )\n\n    class DualLogger:\n        def __init__(self, file_handler):\n            self.file_handler = file_handler\n            self.logger = structlog.get_logger()\n\n        def log(self, event, **kwargs):\n            log_entry = json.dumps({\"event\": event, \"timestamp\": time.time(), **kwargs})\n            self.file_handler.write(log_entry + \"\\n\")\n            self.file_handler.flush()\n\n            if kwargs.get(\"prnt\", True):\n                if \"step\" in kwargs and \"max_steps\" in kwargs:\n                    tqdm.write(f\"[{kwargs.get('step'):>5}/{kwargs.get('max_steps')}] {event}: loss={kwargs.get('loss', 'N/A'):.6f} time={kwargs.get('elapsed_time', 0):.2f}s\")\n                else:\n                    parts = [f\"{k}={v}\" for k, v in kwargs.items() if k not in [\"prnt\", \"timestamp\"]]\n                    if parts:\n                        tqdm.write(f\"{event}: {', '.join(parts)}\")\n                    else:\n                        tqdm.write(event)\n\n    return DualLogger(file_handler)\n\nlogger = None\n\ndef get_titles(num_titles: int, seed: int, val_frac: float) -> str:\n    ds = load_dataset(\"julien040/hacker-news-posts\", split=\"train\", cache_dir=\"./data\").shuffle(seed=seed)\n    titles = [row[\"title\"].strip() for row in ds.take(num_titles)]\n    n = int(num_titles * (1 - val_frac))\n    return titles[:n], titles[n:]\n\ndef get_batch(split_ids: torch.Tensor, ptr: int, block_size: int, batch_size: int, device: torch.device):\n    span = block_size * batch_size + 1\n    if ptr + span >= len(split_ids):\n        ptr = 0\n    batch = split_ids[ptr: ptr + span]\n    x = batch[:-1].view(batch_size, block_size).to(device)\n    y = batch[1:].view(batch_size, block_size).to(device)\n    return x, y, ptr + block_size * batch_size\n\ndef iter_full_split(split_ids: torch.Tensor, block_size: int, batch_size: int, device: torch.device):\n    span = block_size * batch_size + 1\n    for ptr in range(0, len(split_ids) - span + 1, span):\n        batch = split_ids[ptr: ptr + span]\n        x = batch[:-1].view(batch_size, block_size).to(device)\n        y = batch[1:].view(batch_size, block_size).to(device)\n        yield x, y\n\ndef train_tokenizer(titles: list[str], vocab_size: int, unk_token: str = \"<unk>\", pad_token: str = \"<pad>\", eos_token: str = \"<eos>\") -> Tokenizer:\n    tokenizer = Tokenizer(models.BPE(unk_token=unk_token))\n    tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n    tokenizer.decoder = decoders.ByteLevel()\n    trainer = trainers.BpeTrainer(\n        vocab_size=vocab_size,\n        special_tokens=[pad_token, eos_token, unk_token]\n    )\n    tokenizer.train_from_iterator(titles, trainer)\n    return tokenizer\n\nclass BPETokenizer:\n    def __init__(self, tokenizer: Tokenizer):\n        self.tk = tokenizer\n        self.stoi = {tok: i for tok, i in tokenizer.get_vocab().items()}\n        self.itos = {i: tok for tok, i in tokenizer.get_vocab().items()}\n\n    def encode(self, s: str) -> list[int]:\n        return self.tk.encode(s).ids\n\n    def decode(self, ids: list[int]) -> str:\n        return self.tk.decode(ids, skip_special_tokens=True)\n\n    @property\n    def vocab_size(self): return self.tk.get_vocab_size()\n\n@dataclass\nclass GPTConfig:\n    vocab_size: int\n    block_size: int\n    n_layer: int\n    n_head: int\n    d_model: int\n    dropout: float\n\nclass CausalSelfAttention(nn.Module):\n    def __init__(self, cfg: GPTConfig):\n        super().__init__()\n        assert cfg.d_model % cfg.n_head == 0\n        self.head_dim = cfg.d_model // cfg.n_head\n        self.n_head   = cfg.n_head\n        self.qkv = nn.Linear(cfg.d_model, 3 * cfg.d_model)\n        self.proj = nn.Linear(cfg.d_model, cfg.d_model)\n        self.attn_drop = nn.Dropout(cfg.dropout)\n        self.resid_drop= nn.Dropout(cfg.dropout)\n        self.register_buffer(\"tril\", torch.tril(torch.ones(cfg.block_size, cfg.block_size)))\n\n    def forward(self, x: torch.Tensor):\n        B, T, C = x.size()\n        qkv = self.qkv(x).view(B, T, 3, self.n_head, self.head_dim).transpose(1, 3)\n        q, k, v = qkv[..., 0, :, :], qkv[..., 1, :, :], qkv[..., 2, :, :]\n        q = apply_rope(q)\n        k = apply_rope(k)\n        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n        att = att.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\"))\n        att = F.softmax(att, dim=-1)\n        att = self.attn_drop(att)\n        y = att @ v\n        y = y.transpose(1, 2).contiguous().view(B, T, C)\n        return self.resid_drop(self.proj(y))\n\nclass MLP(nn.Module):\n    def __init__(self, cfg: GPTConfig):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(cfg.d_model, 8 * cfg.d_model),\n            nn.GELU(),\n            nn.Linear(8 * cfg.d_model, cfg.d_model),\n            nn.Dropout(cfg.dropout),\n        )\n    def forward(self, x): return self.net(x)\n\nclass Block(nn.Module):\n    def __init__(self, cfg: GPTConfig):\n        super().__init__()\n        self.ln1 = get_norm(cfg.d_model)\n        self.ln2 = get_norm(cfg.d_model)\n        self.attn = CausalSelfAttention(cfg)\n        self.mlp  = MLP(cfg)\n    def forward(self, x):\n        x = x + self.attn(self.ln1(x))\n        x = x + self.mlp(self.ln2(x))\n        return x\n\nclass GPT(nn.Module):\n    def __init__(self, cfg: GPTConfig):\n        super().__init__()\n        self.cfg = cfg\n        self.token_emb = nn.Embedding(cfg.vocab_size, cfg.d_model)\n        self.pos_emb   = nn.Parameter(torch.zeros(1, cfg.block_size, cfg.d_model))\n        self.drop      = nn.Dropout(cfg.dropout)\n        self.blocks    = nn.ModuleList([Block(cfg) for _ in range(cfg.n_layer)])\n        self.ln_f      = get_norm(cfg.d_model)\n        self.head      = nn.Linear(cfg.d_model, cfg.vocab_size, bias=False)\n\n        self.apply(self._init_weights)\n        self.head.weight = self.token_emb.weight\n\n    @staticmethod\n    def _init_weights(module):\n        if isinstance(module, (nn.Linear, nn.Embedding)):\n            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n            if isinstance(module, nn.Linear) and module.bias is not None:\n                nn.init.zeros_(module.bias)\n\n    def forward(self, idx: torch.Tensor, targets: torch.Tensor | None = None):\n        B, T = idx.size()\n        tok = self.token_emb(idx)\n        pos = self.pos_emb[:, :T, :]\n        x = self.drop(tok + pos)\n        for block in self.blocks: x = block(x)\n        x = self.ln_f(x)\n        logits = self.head(x)\n        if targets is None:\n            loss = None\n        else:\n            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), reduction='mean')\n        return logits, loss\n\nargs = Hyperparameters()\ntorch.manual_seed(args.seed)\nrandom.seed(args.seed)\n\nglobal logger\nlogger = configure_logging(args.log_file)\n\nhyperparams_dict = vars(args)\nlogger.log(\"hyperparameters_configured\", **hyperparams_dict)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nlogger.log(\"device_info\", device=device)\n\ntrain_titles, val_titles = get_titles(args.num_titles, args.seed, args.val_frac)\n\neos_token = \"<eos>\"\ntok = BPETokenizer(train_tokenizer(train_titles+val_titles, args.vocab_size, eos_token=eos_token))\ntrain_text = eos_token.join(train_titles) + eos_token\nval_text = eos_token.join(val_titles) + eos_token\ntrain_ids = torch.tensor(tok.encode(train_text), dtype=torch.long)\nval_ids = torch.tensor(tok.encode(val_text), dtype=torch.long)\n\nbatches = len(train_ids) // (args.block_size * args.batch_size)\nmax_steps = args.epochs * batches\neval_interval = batches // args.evals_per_epoch\nlogger.log(\"dataset_info\",\n            titles_count=len(train_titles),\n            epochs=args.epochs,\n            batches_per_epoch=batches,\n            tokens_per_epoch=len(train_ids),\n            vocab_size=tok.vocab_size)\n\ncfg = GPTConfig(\n    vocab_size = tok.vocab_size,\n    block_size = args.block_size,\n    n_layer    = args.n_layer,\n    n_head     = args.n_head,\n    d_model    = args.d_model,\n    dropout    = args.dropout,\n)\nmodel = GPT(cfg).to(device)\nmodel_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nlogger.log(\"model_info\", parameters_count=model_params)\n\nopt = get_optimizer(model, args)\nscheduler = get_scheduler(opt)\n# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=max_steps)\n\ndef evaluate():\n    model.eval()\n    losses = 0.0\n    with torch.no_grad():\n        for xb, yb in iter_full_split(val_ids, args.block_size, args.batch_size, device):\n            logits, _ = model(xb, yb)\n            B, T, V = logits.size()\n            loss = F.cross_entropy(logits.view(-1, V), yb.view(-1), reduction='sum')\n            losses += loss.item()\n    model.train()\n    return losses / len(val_text)\n\nptr = 0\nstep = 0\nt0 = time.time()\nfor epoch in range(1, args.epochs + 1):\n    for _ in tqdm(range(1, batches + 1), desc=f\"Epoch {epoch}/{args.epochs}\"):\n        step += 1\n        xb, yb, ptr = get_batch(train_ids, ptr, args.block_size, args.batch_size, device)\n        _, loss = model(xb, yb)\n        opt.zero_grad(set_to_none=True)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        opt.step()\n        scheduler.step()\n\n        elapsed = time.time() - t0\n        logger.log(\"training_step\",\n                  step=step,\n                  max_steps=max_steps,\n                  loss=loss.item(),\n                  elapsed_time=elapsed,\n                  prnt=False)\n\n        if step == 1 or step % eval_interval == 0 or step == max_steps:\n            val_loss = evaluate()\n            loss_tracker.append(val_loss) # Line added by me\n            logger.log(\"validation_step\",\n                      step=step,\n                      max_steps=max_steps,\n                      loss=val_loss,\n                      elapsed_time=elapsed)","identifier":"prebnmv-ilrf-code","enumerator":"2","html_id":"prebnmv-ilrf-code","key":"FbYWz94qlT"},{"type":"output","id":"dIIyYbbkObQjrdlzFM_jf","data":[{"name":"stdout","output_type":"stream","text":"hyperparameters_configured: block_size=128, batch_size=64, vocab_size=32000, dropout=0.1, weight_decay=0.1, evals_per_epoch=3, epochs=7, seed=1337, num_titles=100000, val_frac=0.1, log_file=./logs/mainrun.log\ndevice_info: device=cuda\ndataset_info: titles_count=90000, epochs=7, batches_per_epoch=123, tokens_per_epoch=1014526, vocab_size=32000\nmodel_info: parameters_count=37452288\n"},{"name":"stderr","output_type":"stream","text":"Epoch 1/7:   1%|          | 1/123 [00:03<07:00,  3.45s/it]"},{"name":"stdout","output_type":"stream","text":"[    1/861] validation_step: loss=1.917966 time=0.03s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 1/7:  33%|███▎      | 41/123 [00:32<02:08,  1.56s/it]"},{"name":"stdout","output_type":"stream","text":"[   41/861] validation_step: loss=1.521273 time=28.56s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 1/7:  67%|██████▋   | 82/123 [01:01<01:01,  1.49s/it]"},{"name":"stdout","output_type":"stream","text":"[   82/861] validation_step: loss=1.468171 time=57.75s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 1/7: 100%|██████████| 123/123 [01:29<00:00,  1.37it/s]\n"},{"name":"stdout","output_type":"stream","text":"[  123/861] validation_step: loss=1.423354 time=86.34s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 2/7:  33%|███▎      | 41/123 [00:29<02:04,  1.52s/it]"},{"name":"stdout","output_type":"stream","text":"[  164/861] validation_step: loss=1.390407 time=115.37s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 2/7:  67%|██████▋   | 82/123 [00:58<01:01,  1.51s/it]"},{"name":"stdout","output_type":"stream","text":"[  205/861] validation_step: loss=1.358058 time=144.42s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 2/7: 100%|██████████| 123/123 [01:27<00:00,  1.41it/s]\n"},{"name":"stdout","output_type":"stream","text":"[  246/861] validation_step: loss=1.334466 time=173.36s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 3/7:  33%|███▎      | 41/123 [00:28<02:03,  1.51s/it]"},{"name":"stdout","output_type":"stream","text":"[  287/861] validation_step: loss=1.322137 time=202.30s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 3/7:  67%|██████▋   | 82/123 [00:57<01:02,  1.51s/it]"},{"name":"stdout","output_type":"stream","text":"[  328/861] validation_step: loss=1.307110 time=231.34s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 3/7: 100%|██████████| 123/123 [01:27<00:00,  1.41it/s]\n"},{"name":"stdout","output_type":"stream","text":"[  369/861] validation_step: loss=1.293728 time=260.42s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 4/7:  33%|███▎      | 41/123 [00:29<02:04,  1.52s/it]"},{"name":"stdout","output_type":"stream","text":"[  410/861] validation_step: loss=1.288369 time=289.57s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 4/7:  67%|██████▋   | 82/123 [00:58<01:02,  1.51s/it]"},{"name":"stdout","output_type":"stream","text":"[  451/861] validation_step: loss=1.278972 time=318.66s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 4/7: 100%|██████████| 123/123 [01:27<00:00,  1.41it/s]\n"},{"name":"stdout","output_type":"stream","text":"[  492/861] validation_step: loss=1.272951 time=347.71s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 5/7:  33%|███▎      | 41/123 [00:29<02:04,  1.51s/it]"},{"name":"stdout","output_type":"stream","text":"[  533/861] validation_step: loss=1.268952 time=376.79s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 5/7:  67%|██████▋   | 82/123 [00:58<01:02,  1.52s/it]"},{"name":"stdout","output_type":"stream","text":"[  574/861] validation_step: loss=1.263219 time=405.87s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 5/7: 100%|██████████| 123/123 [01:27<00:00,  1.41it/s]\n"},{"name":"stdout","output_type":"stream","text":"[  615/861] validation_step: loss=1.258249 time=434.99s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 6/7:  33%|███▎      | 41/123 [00:29<02:04,  1.52s/it]"},{"name":"stdout","output_type":"stream","text":"[  656/861] validation_step: loss=1.256839 time=464.10s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 6/7:  67%|██████▋   | 82/123 [00:58<01:02,  1.51s/it]"},{"name":"stdout","output_type":"stream","text":"[  697/861] validation_step: loss=1.255772 time=493.21s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 6/7: 100%|██████████| 123/123 [01:27<00:00,  1.41it/s]\n"},{"name":"stdout","output_type":"stream","text":"[  738/861] validation_step: loss=1.252785 time=522.29s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 7/7:  33%|███▎      | 41/123 [00:29<02:04,  1.51s/it]"},{"name":"stdout","output_type":"stream","text":"[  779/861] validation_step: loss=1.253220 time=551.34s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 7/7:  67%|██████▋   | 82/123 [00:58<01:02,  1.51s/it]"},{"name":"stdout","output_type":"stream","text":"[  820/861] validation_step: loss=1.252682 time=580.36s\n"},{"name":"stderr","output_type":"stream","text":"Epoch 7/7: 100%|██████████| 123/123 [01:27<00:00,  1.41it/s]"},{"name":"stdout","output_type":"stream","text":"[  861/861] validation_step: loss=1.252463 time=609.39s\n"},{"name":"stderr","output_type":"stream","text":"\n"}],"identifier":"prebnmv-ilrf-output","html_id":"prebnmv-ilrf-output","key":"eVqlwpcOyi"}],"identifier":"prebnmv-ilrf","label":"PreBnMv-Ilrf","html_id":"prebnmv-ilrf","key":"dYNXGDApoh"},{"type":"block","kind":"notebook-code","data":{"colab":{"base_uri":"https://localhost:8080/","height":684},"id":"FuQp3X485HCO","outputId":"b6fd4780-6f79-4a4a-b7b4-6203ffdb9a1a"},"children":[{"type":"code","lang":"python","executable":true,"value":"# |label: token_evaluate_frequency_step_two\nimport matplotlib.pyplot as plt\n\ndef evaluate_visualise():\n    model.eval()\n    losses = 0.0\n\n    with torch.no_grad():\n        for xb, yb in iter_full_split(val_ids, args.block_size, args.batch_size, device):\n\n            logits, _ = model(xb, yb)\n\n            b = 0 # batch\n            t = 80  # timestep\n\n            probs = torch.softmax(logits[b], dim=-1)   # (T, V) out\n\n\n            # displat context\n            prefix_ids = xb[b, :t+1].tolist()\n            prefix_str = tok.tk.decode(prefix_ids, skip_special_tokens=False)\n            print(f\"\\n[CONTEXT up to t={t}]\")\n            print(prefix_str)\n\n            top_probs, top_ids = probs[t].topk(10)\n\n            # decode token strings\n            decoded_tokens = [tok.tk.decode([tid.item()], skip_special_tokens=False) for tid in top_ids ]\n\n            # Print for debugging\n            print(\"\\nTop-10 predictions at t =\", t)\n            for rank in range(10):\n                print(f\"{rank+1}. p={top_probs[rank].item():.4f} | id={top_ids[rank].item()} | '{decoded_tokens[rank]}'\")\n\n            # plt histogram\n            plt.figure(figsize=(12, 5))\n            plt.bar(decoded_tokens, top_probs.cpu().tolist())\n            plt.title(f\"Top-10 Next-Token Predictions (t={t})\")\n            plt.xlabel(\"Token\")\n            plt.ylabel(\"Probability\")\n            plt.xticks(rotation=45, ha='right')\n            plt.tight_layout()\n            plt.show()\n\n            break  # only first batch\nevaluate_visualise()","identifier":"token_predictions_two-code","enumerator":"3","html_id":"token-predictions-two-code","key":"NVeIVbvBpd"},{"type":"output","id":"NZcOVDS5lh59d0TSj4I1K","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"bde12aad412e5e105dde5df45c32c2eb","path":"/bde12aad412e5e105dde5df45c32c2eb.png"},"text/plain":{"content":"<Figure size 1200x500 with 1 Axes>","content_type":"text/plain"}}}],"identifier":"token_predictions_two-output","html_id":"token-predictions-two-output","key":"j4Lps5ZVt7"}],"identifier":"token_predictions_two","label":"token_predictions_two","html_id":"token-predictions-two","key":"V1P8ndJxLx"},{"type":"block","kind":"notebook-code","data":{"colab":{"base_uri":"https://localhost:8080/","height":561},"id":"FuQp3X485HCO","outputId":"cf93278a-99cc-4398-827b-6a379343759b"},"children":[{"type":"code","lang":"python","executable":true,"value":"# |label: token_evaluate_frequency_step_two\nimport matplotlib.pyplot as plt\n\ndef evaluate_visualise():\n    model.eval()\n    losses = 0.0\n\n    with torch.no_grad():\n        for xb, yb in iter_full_split(val_ids, args.block_size, args.batch_size, device):\n\n            logits, _ = model(xb, yb)\n\n            b = 0 # batch\n            t = 10  # timestep\n\n            probs = torch.softmax(logits[b], dim=-1)   # (T, V) out\n\n\n            # displat context\n            prefix_ids = xb[b, :t+1].tolist()\n            prefix_str = tok.tk.decode(prefix_ids, skip_special_tokens=False)\n            print(f\"\\n[CONTEXT up to t={t}]\")\n            print(prefix_str)\n\n            top_probs, top_ids = probs[t].topk(10)\n\n            # decode token strings\n            decoded_tokens = [tok.tk.decode([tid.item()], skip_special_tokens=False) for tid in top_ids ]\n\n            # Print for debugging\n            print(\"\\nTop-10 predictions at t =\", t)\n            for rank in range(10):\n                print(f\"{rank+1}. p={top_probs[rank].item():.4f} | id={top_ids[rank].item()} | '{decoded_tokens[rank]}'\")\n\n            # plt histogram\n            plt.figure(figsize=(12, 5))\n            plt.bar(decoded_tokens, top_probs.cpu().tolist())\n            plt.title(f\"Top-10 Next-Token Predictions (t={t})\")\n            plt.xlabel(\"Token\")\n            plt.ylabel(\"Probability\")\n            plt.xticks(rotation=45, ha='right')\n            plt.tight_layout()\n            plt.show()\n\n            break  # only first batch\nevaluate_visualise()","identifier":"output_step_two_token_10-code","enumerator":"4","html_id":"output-step-two-token-10-code","key":"zBCvwEqGiz"},{"type":"output","id":"uXZxK7aZ4O2RTu06y-Iv7","data":[{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 1200x500 with 1 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"f634fbbc627a4dc7b436ba20ab65091d","path":"/f634fbbc627a4dc7b436ba20ab65091d.png"}}}],"identifier":"output_step_two_token_10-output","html_id":"output-step-two-token-10-output","key":"VZySz5lcjb"}],"identifier":"output_step_two_token_10","label":"output_step_two_token_10","html_id":"output-step-two-token-10","key":"sLrcw676hc"},{"type":"block","kind":"notebook-code","data":{"colab":{"base_uri":"https://localhost:8080/","height":430},"id":"JMHNVftImras","outputId":"4645435c-f658-4e94-e7e3-4628147f9132"},"children":[{"type":"code","lang":"python","executable":true,"value":"# |label: output-second-step\nimport matplotlib.pyplot as plt\n\nplt.plot(loss_tracker)\nplt.show()","identifier":"jmhnvftimras-code","enumerator":"5","html_id":"jmhnvftimras-code","key":"IzXi7HvS2D"},{"type":"output","id":"pvHNQK3KFaOBXi8zkQbLj","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"5434c64e1917528441743ace27580e76","path":"/5434c64e1917528441743ace27580e76.png"},"text/plain":{"content":"<Figure size 640x480 with 1 Axes>","content_type":"text/plain"}}}],"identifier":"jmhnvftimras-output","html_id":"jmhnvftimras-output","key":"gDl5lYCODo"}],"identifier":"jmhnvftimras","label":"JMHNVftImras","html_id":"jmhnvftimras","key":"F12sxML31O"}],"key":"YWZ3wID2BE"},"references":{"cite":{"order":[],"data":{}}}}